{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d869d2-6cb4-4fff-bf23-af454cce0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67683a3a-effc-4ce8-98d5-d45459822b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('env')\n",
    "import pandas as md\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import spacy\n",
    "from importlib import reload\n",
    "from modules import DataCollection, Support\n",
    "reload(Support)\n",
    "reload(DataCollection)\n",
    "from modules.Support import Corpus, Business, TokenCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9508e7fe-61a1-4823-9c80-e7c9a9df2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, os\n",
    "ray.init(num_cpus=os.cpu_count())\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\"\n",
    "import modin.pandas as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009e6a0c-794f-450c-8e4b-f691ef1279fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = DataCollection.s3_client()\n",
    "\n",
    "if not os.path.exists(\"restaurants\"):\n",
    "    os.mkdir(\"restaurants\")\n",
    "    \n",
    "for file_name in ['review.csv', 'business.csv']:\n",
    "    if not os.path.exists(\"restaurants/%s\" % file_name):\n",
    "        s3_client.download_file('s3fld','599Team12/restaurants/%s'% file_name,'restaurants/%s'% file_name) \n",
    "    \n",
    "s3_client.download_file('s3fld','599Team12/negative-words.txt','negative-words.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eec7341-f025-4e85-af25-d8c5449d14d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>hamper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>fainthearted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>incompliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>moronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     negative_words\n",
       "1934         hamper\n",
       "1571   fainthearted\n",
       "2280    incompliant\n",
       "3789           shit\n",
       "2962        moronic"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('negative-words.txt','r') as f:\n",
    "    negative_words = f.read().split('\\n')\n",
    "    \n",
    "# remove heafer information\n",
    "negative_words = negative_words[35:]\n",
    "md.DataFrame(negative_words, columns = ['negative_words']).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e660a7e-ab6d-4df4-8f03-1e1f56979080",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_review = md.read_csv('restaurants/review.csv', compression = 'zip')\n",
    "restaurants_info = md.read_csv('restaurants/business.csv', compression = 'zip')\n",
    "negative_reviews = restaurants_review.query('sentiment == \"negative\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed01a1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207279</th>\n",
       "      <td>byIAYlPnBb5tgj8LvA3bpA</td>\n",
       "      <td>VQcCL9PiNL_wkGf-uF3fjg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Where do I even begin about this disastrous ex...</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>negative</td>\n",
       "      <td>Royal House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510475</th>\n",
       "      <td>FUlN4fCfMIWvbKf5YXAKJQ</td>\n",
       "      <td>NieQEbxG4Aqkhqj0h2TRtg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>If employees are unable to have online orders ...</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>negative</td>\n",
       "      <td>Port of Subs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66876</th>\n",
       "      <td>-pzlOJ-Brj1i_C9NXIKWzA</td>\n",
       "      <td>31s1x27DnN2V-ptUWEdfTQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Oh my goodness! Walking to get sandwiches for ...</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>negative</td>\n",
       "      <td>Subway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740935</th>\n",
       "      <td>C_CJk1CXTgSW-ZCXdHpazw</td>\n",
       "      <td>t5Xc0u9yvOH0-DgmrCS60Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Discriminate against the lactose intolerant! T...</td>\n",
       "      <td>2012-01-07</td>\n",
       "      <td>negative</td>\n",
       "      <td>Pirrone's Pizzeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860501</th>\n",
       "      <td>5Ys1fJwlQaVRO9l_0yfecw</td>\n",
       "      <td>lUiY3W4JOdpWBXq32KvDGw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>We have a friend who LOVES Waffles on Maple. W...</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>negative</td>\n",
       "      <td>Waffles on Maple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id             business_id  stars  \\\n",
       "207279  byIAYlPnBb5tgj8LvA3bpA  VQcCL9PiNL_wkGf-uF3fjg    1.0   \n",
       "510475  FUlN4fCfMIWvbKf5YXAKJQ  NieQEbxG4Aqkhqj0h2TRtg    2.0   \n",
       "66876   -pzlOJ-Brj1i_C9NXIKWzA  31s1x27DnN2V-ptUWEdfTQ    1.0   \n",
       "740935  C_CJk1CXTgSW-ZCXdHpazw  t5Xc0u9yvOH0-DgmrCS60Q    1.0   \n",
       "860501  5Ys1fJwlQaVRO9l_0yfecw  lUiY3W4JOdpWBXq32KvDGw    2.0   \n",
       "\n",
       "                                                     text        date  \\\n",
       "207279  Where do I even begin about this disastrous ex...  2018-03-18   \n",
       "510475  If employees are unable to have online orders ...  2016-09-27   \n",
       "66876   Oh my goodness! Walking to get sandwiches for ...  2020-07-05   \n",
       "740935  Discriminate against the lactose intolerant! T...  2012-01-07   \n",
       "860501  We have a friend who LOVES Waffles on Maple. W...  2017-04-03   \n",
       "\n",
       "       sentiment                name  \n",
       "207279  negative         Royal House  \n",
       "510475  negative        Port of Subs  \n",
       "66876   negative              Subway  \n",
       "740935  negative  Pirrone's Pizzeria  \n",
       "860501  negative    Waffles on Maple  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# negative_reviews.date is date only\n",
    "negative_reviews['date'] = md.to_datetime(negative_reviews['date'])\n",
    "negative_reviews['date'] = negative_reviews['date'].dt.date\n",
    "\n",
    "# if a column name Unnamed: 0 exists, then drop it\n",
    "if 'Unnamed: 0' in negative_reviews.columns:\n",
    "    negative_reviews.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    \n",
    "# use restaurants_review to get the business name\n",
    "negative_reviews = negative_reviews.merge(\n",
    "    restaurants_info[['business_id', 'name']], \n",
    "    on='business_id', \n",
    "    how='left')\n",
    " \n",
    "negative_reviews = negative_reviews.reset_index(drop=True)\n",
    "negative_reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251fd5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "McDonald's                14173\n",
       "Taco Bell                  5994\n",
       "Chipotle Mexican Grill     5628\n",
       "Wendy's                    4680\n",
       "Buffalo Wild Wings         4472\n",
       "Steak ’n Shake             4458\n",
       "Domino's Pizza             4448\n",
       "Burger King                4004\n",
       "Panera Bread               3779\n",
       "Chili's                    3673\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of name in negative_reviews and sort by count\n",
    "business_name_counts = negative_reviews.name.value_counts().sort_values(ascending=False)\n",
    "business_name_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a8a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "tc = TokenCleaner(return_as_string=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58757cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prejudic',\n",
       " 'vocifer',\n",
       " 'insoci',\n",
       " 'hothead',\n",
       " 'recessionari',\n",
       " 'scourg',\n",
       " 'maladjust',\n",
       " 'discredit',\n",
       " 'collaps',\n",
       " 'clash']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative_words_roots = tc.CleanText(' '.join(negative_words))\n",
    "negative_words_roots = set(negative_words_roots)\n",
    "\n",
    "# show 10 random root words\n",
    "list(negative_words_roots)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c8ac379",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17144/1902179676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get the top negative words used in the whole negative reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCleanText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negative_words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnegative_words_roots\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1157\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17144/1902179676.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get the top negative words used in the whole negative reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCleanText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negative_words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnegative_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnegative_words_roots\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Repository\\599_stage\\modules\\Support.py\u001b[0m in \u001b[0;36mCleanText\u001b[1;34m(self, _text)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__RemovePunctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__TokenizeText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__StemEachToken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__RemoveStopWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Repository\\599_stage\\modules\\Support.py\u001b[0m in \u001b[0;36m__StemEachToken\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \"\"\"\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__add_space_before_and_after_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Repository\\599_stage\\modules\\Support.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \"\"\"\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__add_space_before_and_after_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\stem\\porter.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word, to_lowercase)\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step1b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step1c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\stem\\porter.py\u001b[0m in \u001b[0;36m_step1a\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replace_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ies\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ie\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         return self._apply_rule_list(\n\u001b[0m\u001b[0;32m    294\u001b[0m             \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             [\n",
      "\u001b[1;32mc:\\Users\\nimat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\stem\\porter.py\u001b[0m in \u001b[0;36m_apply_rule_list\u001b[1;34m(self, word, rules)\u001b[0m\n\u001b[0;32m    264\u001b[0m                     \u001b[1;31m# Don't try any further rules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m                 \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replace_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the top negative words used in the whole negative reviews\n",
    "negative_reviews['tokenized'] = negative_reviews['text'].apply(lambda x: tc.CleanText(x))\n",
    "negative_reviews['negative_words'] = \\\n",
    "    negative_reviews['tokenized'].apply(lambda x: [word for word in x if word in negative_words_roots])\n",
    "\n",
    "# create a dic that has count of each negative words used in the whole negative reviews\n",
    "negative_words_count = Counter(chain.from_iterable(negative_reviews['negative_words']))\n",
    "negative_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af815a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_to_do = business_name_counts.index[:5]\n",
    "restaurants_to_do = ['Chipotle Mexican Grill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa766881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for business_name in restaurants_to_do:\n",
    "    reviews = negative_reviews.query('name == @business_name')\n",
    "    reviews.reset_index(drop=True, inplace=True)\n",
    "    reviews['tokenized'] = reviews['text'].apply(tc.CleanText)\n",
    "    words = Counter(chain.from_iterable(reviews['tokenized']))\n",
    "    \n",
    "    # remove if not a negative word\n",
    "    words = {k:v for k,v in words.items() if k in negative_words_roots}\n",
    "    \n",
    "    info = restaurants_info.query('name == @business_name')\n",
    "    business = Business(info, reviews, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9eee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_names = ['Chipotle Mexican Grill']\n",
    "\n",
    "for business_name in business_names:\n",
    "    info = business_names[business_names ]\n",
    "    business = Business(business_name)\n",
    "    business.negative_reviews = negative_reviews[negative_reviews.business_name == business_name]\n",
    "    business.word_counts = word_counts[word_counts.business_name == business_name]\n",
    "    corpus.businesses[business_name] = business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505dbfc-5313-465a-ad30-539934c4648d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in word_counts.iterrows():\n",
    "    # count how many time each root word was used in review with negative sentiment\n",
    "    word_to_look_for = row.word\n",
    "    occurance = negative_reviews['text_cleaned'].apply(lambda x: x.count(word_to_look_for)).sum()\n",
    "    word_counts.loc[index, 'negative_use'] = occurance\n",
    "    print('{:0>3} | \"{}\" was used {:,} times in the negative reviews.'.format(index, word_to_look_for, occurance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be14faf-be74-4542-9da6-11b4cfb3e647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe21f82-de1e-40c8-9935-9a7df23a22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = DataCollection.s3_client()\n",
    "\n",
    "if not os.path.exists(\"analysis\"):\n",
    "    os.mkdir(\"analysis\")\n",
    "    \n",
    "negative_reviews.to_csv('analysis/negative_reviews.csv', compression = 'zip')\n",
    "s3_client.upload_file('analysis/negative_reviews.csv', 's3fld', '599Team12/analysis/negative_reviews.csv', ExtraArgs={'ACL': 'public-read'})\n",
    "\n",
    "word_counts.to_csv('analysis/word_counts.csv', compression = 'zip')\n",
    "s3_client.upload_file('analysis/word_counts.csv', 's3fld', '599Team12/analysis/word_counts.csv', ExtraArgs={'ACL': 'public-read'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad61851-3600-4859-8d6c-81e2e6867dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcea64e4f4c529eb8d3804d742208b49cf576db861fb82da362bb9eddfc00d80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
